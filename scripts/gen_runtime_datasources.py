import json
import re
from pathlib import Path

SPEC_PATH = Path('spec/openapi.json')
OUT_DIR = Path('internal/provider')

SPEC = json.load(open(SPEC_PATH))

# Utility

def singularize(segment: str) -> str:
    if segment.endswith('ies') and len(segment) > 3:
        return segment[:-3] + 'y'
    if segment.endswith('sses'):
        return segment[:-2]
    if segment.endswith('s') and not segment.endswith('ss'):
        return segment[:-1]
    return segment

def go_ident(name: str) -> str:
    parts = re.split(r'[_\-]', name)
    return ''.join(p[:1].upper() + p[1:] for p in parts if p)

def attr_go_type(param_name: str) -> str:
    if param_name == 'index':
        return 'types.Int64'
    return 'types.String'

def value_string_expr(var: str, param_name: str) -> str:
    if param_name == 'index':
        return f'int64ToString({var}.ValueInt64())'
    return f'{var}.ValueString()'

def tf_param_name(param_name: str) -> str:
    name = re.sub(r'[^a-z0-9_]', '_', param_name.lower())
    if name == 'id':
        return 'runtime_id'
    return name

paths = SPEC['paths']
runtime_paths = {p: paths[p] for p in paths if p.startswith('/services/haproxy/runtime')}

datasources = []

for path, item in runtime_paths.items():
    if 'get' not in item:
        continue

    get = item['get']
    resp = get.get('responses', {}).get('200', {}).get('content', {}).get('application/json', {}).get('schema')
    if not resp:
        continue

    schema_name = None
    is_array = False
    is_scalar = False

    if '$ref' in resp:
        schema_name = resp['$ref'].split('/')[-1]
        schema = SPEC['components']['schemas'].get(schema_name, {})
        if schema.get('type') == 'array':
            is_array = True
            schema_name = schema.get('items', {}).get('$ref', '').split('/')[-1]
    elif resp.get('type') == 'array':
        is_array = True
        items = resp.get('items', {})
        if '$ref' in items:
            schema_name = items['$ref'].split('/')[-1]
    elif resp.get('type') in ['integer', 'string', 'number', 'boolean']:
        is_scalar = True
    else:
        continue

    segments = path.rstrip('/').split('/')
    rel_segments = segments[4:]
    rel_literals = [s for s in rel_segments if not s.startswith('{')]
    rel_literals = [singularize(s) for s in rel_literals]
    ds_name = 'runtime_' + '_'.join(rel_literals)

    params = get.get('parameters', [])
    path_params = []
    query_params = []
    for p in params:
        if not p.get('required'):
            continue
        if p.get('in') == 'path':
            path_params.append(p['name'])
        elif p.get('in') == 'query':
            query_params.append(p['name'])

    datasources.append({
        'name': ds_name,
        'path': path,
        'schema': schema_name,
        'path_params': path_params,
        'query_params': query_params,
        'is_array': is_array,
        'is_scalar': is_scalar,
        'scalar_type': resp.get('type') if is_scalar else None,
    })

seen = set()
unique = []
for d in datasources:
    if d['name'] in seen:
        continue
    seen.add(d['name'])
    unique.append(d)

datasources = sorted(unique, key=lambda d: d['name'])

with open(OUT_DIR / 'runtime_datasources_gen.go', 'w') as f:
    f.write("// Code generated by scripts/gen_runtime_datasources.py. DO NOT EDIT.\n")
    f.write("package provider\n\n")
    f.write("import (\n\t\"github.com/hashicorp/terraform-plugin-framework/datasource\"\n)\n\n")
    f.write("func generatedRuntimeDataSources() []func() datasource.DataSource {\n\treturn []func() datasource.DataSource{\n")
    for d in datasources:
        f.write(f"\t\tNew{go_ident(d['name'])}DataSource,\n")
    f.write("\t}\n}\n")

for d in datasources:
    name = d['name']
    type_name = go_ident(name)
    path_params = d['path_params']
    query_params = d['query_params']

    fields = []
    for p in path_params + query_params:
        tf_name = tf_param_name(p)
        go_type = attr_go_type(p)
        fields.append((go_ident(tf_name), go_type, tf_name, p))

    param_schema_lines = []
    for p in path_params + query_params:
        attr_type = 'String' if p != 'index' else 'Int64'
        param_schema_lines.append(f"\t\t\t\"{tf_param_name(p)}\": schema.{attr_type}Attribute{{Required: true}},\n")

    def query_lines(var_prefix: str):
        lines = []
        for p in query_params:
            field = go_ident(tf_param_name(p))
            lines.append(f"\t\t\t\"{p}\": []string{{{value_string_expr(var_prefix+field, p)}}},\n")
        return lines

    def path_lines(var_prefix: str):
        lines = []
        for p in path_params:
            field = go_ident(tf_param_name(p))
            lines.append(f"\t\t\t\"{p}\": {value_string_expr(var_prefix+field, p)},\n")
        return lines

    with open(OUT_DIR / f'gen_data_source_{name}.go', 'w') as f:
        f.write("// Code generated by scripts/gen_runtime_datasources.py. DO NOT EDIT.\n")
        f.write("package provider\n\n")
        f.write("import (\n\t\"context\"\n\t\"net/url\"\n\t\"strings\"\n\n\t\"github.com/hashicorp/terraform-plugin-framework/datasource\"\n\t\"github.com/hashicorp/terraform-plugin-framework/datasource/schema\"\n\t\"github.com/hashicorp/terraform-plugin-framework/types\"\n\t\"github.com/pderuiter/terraform-provider-haproxy-dataplane/internal/client\"\n)\n\n")
        f.write(f"var _ datasource.DataSource = (*{name}DataSource)(nil)\n\n")
        f.write(f"func New{type_name}DataSource() datasource.DataSource {{\n\treturn &{name}DataSource{{}}\n}}\n\n")
        f.write(f"type {name}DataSource struct {{\n\tclient *client.Client\n}}\n\n")

        f.write(f"type {name}DataSourceModel struct {{\n")
        for field, go_type, tf_name, _ in fields:
            f.write(f"\t{field} {go_type} `tfsdk:\"{tf_name}\"`\n")
        if d['is_scalar']:
            f.write("\tValue types.String `tfsdk:\"value\"`\n" if d['scalar_type'] == 'string' else "\tValue types.Int64 `tfsdk:\"value\"`\n")
        elif d['is_array']:
            f.write("\tItems types.Dynamic `tfsdk:\"items\"`\n")
        else:
            f.write("\tSpec types.Object `tfsdk:\"spec\"`\n")
        f.write("\tID types.String `tfsdk:\"id\"`\n}\n\n")

        f.write(f"func (d *{name}DataSource) Metadata(ctx context.Context, req datasource.MetadataRequest, resp *datasource.MetadataResponse) {{\n\tresp.TypeName = req.ProviderTypeName + \"_{name}\"\n}}\n\n")
        f.write(f"func (d *{name}DataSource) Schema(ctx context.Context, req datasource.SchemaRequest, resp *datasource.SchemaResponse) {{\n")
        if d['is_scalar']:
            f.write("\tresp.Schema = schema.Schema{\n\t\tAttributes: map[string]schema.Attribute{\n")
        elif not d['is_array']:
            f.write("\tattrs, ok := schemaAttributesForDataSource(\"%s\")\n" % d['schema'])
            f.write("\tif !ok {\n\t\tresp.Diagnostics.AddError(\"Schema not found\", \"%s\")\n\t\treturn\n\t}\n" % d['schema'])
            f.write("\tresp.Schema = schema.Schema{\n\t\tAttributes: map[string]schema.Attribute{\n")
        else:
            f.write("\tresp.Schema = schema.Schema{\n\t\tAttributes: map[string]schema.Attribute{\n")
        for line in param_schema_lines:
            f.write(line)
        if d['is_scalar']:
            f.write("\t\t\t\"value\": schema.Int64Attribute{Computed: true},\n" if d['scalar_type'] != 'string' else "\t\t\t\"value\": schema.StringAttribute{Computed: true},\n")
        elif d['is_array']:
            f.write("\t\t\t\"items\": schema.DynamicAttribute{Computed: true},\n")
        else:
            f.write("\t\t\t\"spec\": schema.SingleNestedAttribute{Computed: true, Attributes: attrs},\n")
        f.write("\t\t\t\"id\": schema.StringAttribute{Computed: true},\n")
        f.write("\t\t},\n\t}\n}\n\n")

        f.write(f"func (d *{name}DataSource) Configure(ctx context.Context, req datasource.ConfigureRequest, resp *datasource.ConfigureResponse) {{\n")
        f.write("\tif req.ProviderData == nil {\n\t\treturn\n\t}\n")
        f.write("\tclient, diags := getClient(req.ProviderData)\n\tresp.Diagnostics.Append(diags...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\tif client != nil {\n\t\td.client = client\n\t}\n}\n\n")

        f.write(f"func (d *{name}DataSource) Read(ctx context.Context, req datasource.ReadRequest, resp *datasource.ReadResponse) {{\n")
        f.write(f"\tvar state {name}DataSourceModel\n\tresp.Diagnostics.Append(req.Config.Get(ctx, &state)...)\n\tif resp.Diagnostics.HasError() {{\n\t\treturn\n\t}}\n")
        f.write("\tquery := url.Values{\n")
        for line in query_lines('state.'):
            f.write(line)
        f.write("\t}\n")
        f.write("\tpath := buildPath(\"%s\", map[string]string{\n" % d['path'])
        for line in path_lines('state.'):
            f.write(line)
        f.write("\t})\n")
        if d['is_scalar']:
            if d['scalar_type'] == 'string':
                f.write("\tvar out string\n\tif err := d.client.GetJSON(ctx, path, query, &out); err != nil {\n\t\tresp.Diagnostics.AddError(\"Read failed\", err.Error())\n\t\treturn\n\t}\n\tstate.Value = types.StringValue(out)\n")
            else:
                f.write("\tvar out int64\n\tif err := d.client.GetJSON(ctx, path, query, &out); err != nil {\n\t\tresp.Diagnostics.AddError(\"Read failed\", err.Error())\n\t\treturn\n\t}\n\tstate.Value = types.Int64Value(out)\n")
        elif d['is_array']:
            f.write("\tvar out []map[string]any\n\tif err := d.client.GetJSON(ctx, path, query, &out); err != nil {\n\t\tresp.Diagnostics.AddError(\"Read failed\", err.Error())\n\t\treturn\n\t}\n")
            f.write("\titems, diags := listObjectsFromSchema(ctx, \"%s\", out)\n" % d['schema'])
            f.write("\tresp.Diagnostics.Append(diags...)\n\tstate.Items = types.DynamicValue(items)\n")
        else:
            f.write("\tvar out map[string]any\n\tif err := d.client.GetJSON(ctx, path, query, &out); err != nil {\n\t\tresp.Diagnostics.AddError(\"Read failed\", err.Error())\n\t\treturn\n\t}\n")
            f.write("\tobj, diags := mapToObjectWithSchema(ctx, \"%s\", out, []string{})\n" % d['schema'])
            f.write("\tresp.Diagnostics.Append(diags...)\n\tstate.Spec = obj\n")
        f.write("\tstate.ID = types.StringValue(strings.Join([]string{\"%s\"}, \"/\"))\n" % name)
        f.write("\tresp.Diagnostics.Append(resp.State.Set(ctx, &state)...)\n}\n")

print(f"Generated {len(datasources)} runtime data sources")
